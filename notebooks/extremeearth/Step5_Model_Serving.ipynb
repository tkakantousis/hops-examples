{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Serving The Trained Model for Classifying TinyImageNet. Notebook (4/4) in the End-to-End Scalable Deep Learning Pipeline on Hops.\n",
    "\n",
    "\n",
    "This notebook will send inference requests to a model serving instance that was exported by notebook number three ([Notebook number three](./Step3_Distributed_Training.ipynb)). This assumes that you have created a model serving instance of the model by using the hopsworks UI. You can find documentation on how to do this [here](https://hops.readthedocs.io/en/0.9/hopsml/model_serving.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%local\n",
    "import requests\n",
    "from hops import util\n",
    "from hops import hdfs\n",
    "from hops import constants\n",
    "import os\n",
    "from hops import featurestore\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from hops import serving\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%local\n",
    "MODEL = \"icebergmodel\"\n",
    "PROJECT = hdfs.project_name()\n",
    "INFERENCE_URL = (\"/\" + \n",
    "                 constants.REST_CONFIG.HOPSWORKS_REST_RESOURCE + \n",
    "                 \"/project/\" + \n",
    "                 str(hdfs.project_id()) + \n",
    "                 \"/inference/models/\" + \n",
    "                 MODEL + \n",
    "                 \":predict\"\n",
    "                )\n",
    "SERVER = \"\"\n",
    "WORK_DIR = \"\"\n",
    "CONCURRENCY = \"\"\n",
    "NUM_TESTS = \"\"\n",
    "TEST_DATASET = \"train_tfrecords_iceberg_classification_dataset\"\n",
    "HEIGHT = 75\n",
    "WIDTH = 75\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 10000\n",
    "INPUT_SHAPE = 16875\n",
    "NUM_CLASSES = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%local\n",
    "def get_tf_dataset():\n",
    "    tf_record_schema = featurestore.get_training_dataset_tf_record_schema(TEST_DATASET)\n",
    "    dataset_dir = featurestore.get_training_dataset_path(TEST_DATASET)\n",
    "    input_files = tf.gfile.Glob(dataset_dir + \"/part-r-*\")\n",
    "    dataset = tf.data.TFRecordDataset(input_files)\n",
    "\n",
    "    def decode(example_proto):\n",
    "        name_list = [\"band_1\", \"band_2\", \"band_avg\", \"is_iceberg\"]\n",
    "        example = tf.parse_single_example(example_proto, tf_record_schema)\n",
    "        x = tf.stack([example[name_list[0]], example[name_list[1]], example[name_list[2]]], axis=1)\n",
    "        x = tf.reshape(x, [75, 75, 3])\n",
    "        y = [tf.cast(example[name_list[3]], tf.float32)]\n",
    "        return x,y\n",
    "    \n",
    "    dataset = dataset.map(decode)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%local\n",
    "def do_inference():\n",
    "    with tf.Session() as sess:\n",
    "        dataset = get_tf_dataset()\n",
    "        dataset_iter = dataset.make_one_shot_iterator()\n",
    "        next_element = dataset_iter.get_next()\n",
    "        for i in range(10):\n",
    "            x,y = sess.run(next_element)\n",
    "            request_data={}\n",
    "            request_data['instances'] = [x.tolist()]\n",
    "            response = serving.make_inference_request(\"icebergmodel\", data=request_data, verb= \":predict\")\n",
    "            print(\"prediction: {}, is_iceberg: {}\".format(response['predictions'][0][0], y[0]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 0.457645357, is_iceberg: 0.0\n",
      "prediction: 0.457955331, is_iceberg: 0.0\n",
      "prediction: 0.469079971, is_iceberg: 0.0\n",
      "prediction: 0.458596766, is_iceberg: 1.0\n",
      "prediction: 0.458393067, is_iceberg: 1.0\n",
      "prediction: 0.459837317, is_iceberg: 1.0\n",
      "prediction: 0.456256419, is_iceberg: 0.0\n",
      "prediction: 0.457359701, is_iceberg: 0.0\n",
      "prediction: 0.457865953, is_iceberg: 0.0\n",
      "prediction: 0.458710402, is_iceberg: 0.0\n"
     ]
    }
   ],
   "source": [
    "%local\n",
    "do_inference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}